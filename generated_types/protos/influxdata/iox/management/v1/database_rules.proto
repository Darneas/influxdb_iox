syntax = "proto3";
package influxdata.iox.management.v1;
option go_package = "github.com/influxdata/iox/management/v1";

import "google/protobuf/duration.proto";
import "google/protobuf/empty.proto";
import "influxdata/iox/management/v1/shard.proto";

// `PartitionTemplate` is used to compute the partition key of each row that
// gets written. It can consist of the table name, a column name and its value,
// a formatted time, or a string column and regex captures of its value. For
// columns that do not appear in the input row, a blank value is output.
//
// The key is constructed in order of the template parts; thus ordering changes
// what partition key is generated.
message PartitionTemplate {
  message Part {
    message ColumnFormat {
      string column = 1;
      string format = 2;
    }

    oneof part {
      google.protobuf.Empty table = 1;
      string column = 2;
      string time = 3;
      ColumnFormat regex = 4;
      ColumnFormat strf_time = 5;
    }
  }

  repeated Part parts = 1;
}

message LifecycleRules {
  // Once the total amount of buffered data in memory reaches this size start
  // dropping data from memory
  uint64 buffer_size_soft = 4;

  // Once the amount of data in memory reaches this size start
  // rejecting writes
  uint64 buffer_size_hard = 5;

  // 7 once was `drop_non_persisted`
  reserved 7;

  // Persists chunks to object storage.
  bool persist = 9;

  // Do not allow writing new data to this database
  bool immutable = 8;

  // If the background worker doesn't find any work to do it will
  // sleep for this many milliseconds before looking again
  //
  // If 0, the default backoff is used
  // See server::db::lifecycle::DEFAULT_LIFECYCLE_BACKOFF
  uint64 worker_backoff_millis = 10;

  // After how many transactions should IOx write a new checkpoint?
  //
  // If 0 / absent, this default to 100.
  uint64 catalog_transactions_until_checkpoint = 11;

  /// Once a partition hasn't received a write for this period of time,
  /// it will be compacted and, if set, persisted. Writers will generally
  /// have this amount of time to send late arriving writes or this could
  /// be their clock skew.
  uint32 late_arrive_window_seconds = 12;

  // Maximum number of rows before triggering persistence
  uint64 persist_row_threshold = 13;

  // Maximum age of a write before triggering persistence
  uint32 persist_age_threshold_seconds = 14;

  // Maximum number of rows to buffer in a MUB chunk before compacting it
  uint64 mub_row_threshold = 15;

  oneof max_active_compactions_cfg {
    // The maximum number of concurrent active compactions that can run.
    uint32 max_active_compactions = 16;

    // The maximum number of concurrent active compactions that can run
    // expressed as a fraction of the available cpus (rounded to the next smallest non-zero integer).
    float max_active_compactions_cpu_fraction = 18;
  }

  // Use up to this amount of space in bytes for caching Parquet files.
  // A value of 0 disables Parquet caching
  uint64 parquet_cache_limit = 17;
}

message DatabaseRules {
  // The unencoded name of the database
  string name = 1;

  // Template that generates a partition key for each row inserted into the database
  PartitionTemplate partition_template = 2;

  // Configures how data flows through the system
  LifecycleRules lifecycle_rules = 3;

  oneof routing_rules {
    // Shard config
    ShardConfig shard_config = 8;

    // Routing config
    RoutingConfig routing_config = 9;
  }

  // Duration for which the cleanup loop should sleep on average.
  // Defaults to 500 seconds.
  google.protobuf.Duration worker_cleanup_avg_sleep = 10;

  // These were the old write buffer connection strings.
  reserved 11, 12;

  // Optionally, the connection for the write buffer for writing or reading/restoring data.
  WriteBufferConnection write_buffer_connection = 13;
}

// Configures the use of a write buffer.
message WriteBufferConnection {
  enum Direction {
    // Unspecified direction, will be treated as an error.
    DIRECTION_UNSPECIFIED = 0;

    // Writes into the buffer aka "producer".
    DIRECTION_WRITE = 1;

    // Reads from the buffer aka "consumer".
    DIRECTION_READ = 2;
  }

  // If the buffer is used for reading or writing.
  Direction direction = 1;

  // Which type should be used (e.g. "kafka", "mock")
  string type = 2;

  // Connection string, depends on `type`.
  string connection = 3;

  // Number of sequencers.
  //
  // Defaults to 1.
  //
  // How they are implemented depends on `type`, e.g. for Kafka this is mapped to the number of partitions.
  uint32 n_sequencers = 4;

  // Special configs to by applied when sequencers are created.
  //
  // This depends on `type` and can setup parameters like retention policy.
  map<string, string> creation_config = 5;

  // Special configs to be applied when establishing the connection.
  //
  // This depends on `type` and can configure aspects like timeouts.
  map<string, string> connection_config = 6;
}

message RoutingConfig {
  Sink sink = 2;
}
